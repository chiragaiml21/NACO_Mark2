{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chirag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chirag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D://Study Material//My AI's//Mark 2//intents.json\", 'r', encoding='utf8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Dependent, Independent, Lemmatizer, Stemmer Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = data['intents']\n",
    "X = []\n",
    "y = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Function is for the preprocessing of data before fitting it in model. Various NLP techniques are used here to preprocess the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Normalize text (convert to lowercase and remove non-alphanumeric characters)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)   #Substitute the matched string in text with space.\n",
    "\n",
    "    # Stemming\n",
    "    stemmed_words = [stemmer.stem(word) for word in text.split()]\n",
    "\n",
    "    #tokenize\n",
    "    tokenized_words = word_tokenize(text)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokenized_words]   #changing, Changed---->change\n",
    "\n",
    "    # Join the preprocessed words back into a single string\n",
    "    processed_text = \" \".join(lemmatized_words)\n",
    "    return processed_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the Dependent and Independent values after preprocessing the data and storing it in X(Independent) and y(Dependent) variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents:\n",
    "    tag = intent['tag']\n",
    "    patterns = intent['patterns']\n",
    "    for pattern in patterns:\n",
    "        processed_pattern = preprocess_text(pattern)\n",
    "        X.append(processed_pattern)\n",
    "        y.append(tag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and testing data, here the ration is 80:20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and fit the training data in the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;svm&#x27;, SVC(C=1.5, kernel=&#x27;linear&#x27;, probability=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;svm&#x27;, SVC(C=1.5, kernel=&#x27;linear&#x27;, probability=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1.5, kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('svm', SVC(C=1.5, kernel='linear', probability=True))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('svm', SVC(kernel='linear', C=1.5, probability=True))\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the accuracy of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Recognition Accuracy: 73.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Intent Recognition Accuracy: {accuracy*100}%\")\n",
    "#Initially the model accuracy is 57.14285714285714%, but after adding more data to the intents.json file, the accuracy increased to 85.71428571428571%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store conversation history\n",
    "conversation_history = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Recognising the Intent of user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_intent(message):\n",
    "    processed_message = preprocess_text(message)\n",
    "    intent = model.predict([processed_message])[0]\n",
    "    print(\"Intent = \",intent)\n",
    "    print(\"Probability = \",model.predict_proba([message]))\n",
    "    return intent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion for getting response on the basis for intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bot_response(intent, history):\n",
    "    for intent_data in intents:\n",
    "        if intent_data['tag'] == intent:\n",
    "            responses = intent_data['responses']\n",
    "            # Modify the response generation based on the conversation history\n",
    "            # Example logic: Access the last user input and provide a relevant response\n",
    "            last_user_input = history[-1]['patterns']\n",
    "            if last_user_input == 'help':\n",
    "                return \"I see you need help. How can I assist you?\"\n",
    "\n",
    "            return random.choice(responses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to initialize the chatbot with some personalized features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    \n",
    "    print(\"Bot: Hello! {User} How can I assist you?\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"{User}: \")\n",
    "        if user_input.lower() in [\"stop\", \"quit\"]:\n",
    "            print(\"Bot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        elif user_input == \"\":\n",
    "            print(\"Bot: You have not entered anything, Please enter a message.\")\n",
    "            continue\n",
    "\n",
    "        recognized_intent = recognize_intent(user_input)\n",
    "        conversation_history.append({'tag': recognized_intent, 'patterns': user_input})\n",
    "\n",
    "        last_user_input = conversation_history[-1]['patterns']\n",
    "        last_intent = conversation_history[-1]['tag']\n",
    "\n",
    "        bot_response = get_bot_response(last_intent, conversation_history)\n",
    "\n",
    "        conversation_history[-1].update(responses= bot_response)\n",
    "\n",
    "        print(\"Bot:\", bot_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call the chatbot function and at the end the conversation history saved and in near future we'll gonna use it for traing our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Start():\n",
    "    # heyhey = input(f\"Do you want me to call you {User} from now on or I call you BOSS? ----> \")\n",
    "    # if heyhey.lower() == \"boss\":\n",
    "    #   User = \"BOSS\"\n",
    "    # elif heyhey.lower() in [\"yes\", f'{User}']:\n",
    "    #   User = User\n",
    "    # else:\n",
    "    #    print(\"Please enter a valid input\")\n",
    "    #    Start(User)\n",
    "      \n",
    "    print(f\"I'm your personal assistant. I can help you with your queries. If you want to stop this conversation, just type 'stop' or 'quit' and I'll stop our conversation.\")\n",
    "    chatbot()\n",
    "    print(\"\\n*****This is your conversation history, which we'll gonna use to train our model*****\\n\\n\",\"Intent : \",\n",
    "      [i['tag'] for i in conversation_history],\"\\n\",\"User Input : \",\n",
    "      [i['patterns'] for i in conversation_history],\"\\n\",\"Bot Responses : \",\n",
    "      [i['responses'] for i in conversation_history]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START.........Run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm your personal assistant. I can help you with your queries. If you want to stop this conversation, just type 'stop' or 'quit' and I'll stop our conversation.\n",
      "Bot: Hello! {User} How can I assist you?\n",
      "Intent =  greeting\n",
      "Probability =  [[0.06304458 0.01878875 0.06794946 0.5440037  0.02410129 0.02894321\n",
      "  0.04461576 0.03078252 0.03199748 0.0730461  0.05332812 0.01939904]]\n",
      "Bot: Hi, hi, hi! What's the latest gossip?\n",
      "Bot: Goodbye! Have a great day!\n",
      "\n",
      "*****This is your conversation history, which we'll gonna use to train our model*****\n",
      "\n",
      " Intent :  ['greeting'] \n",
      " User Input :  ['hello'] \n",
      " Bot Responses :  [\"Hi, hi, hi! What's the latest gossip?\"]\n"
     ]
    }
   ],
   "source": [
    "Start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial for merging branch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
